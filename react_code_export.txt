// File: frontend/app.py
import os
# Disable Streamlit's file watcher to avoid torch.classes errors on Python 3.12
os.environ["STREAMLIT_WATCHED_FILES"] = "[]"

import sys, base64
from io import BytesIO
# Ensure the project root is added to the Python path.
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import streamlit as st
import random
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

# Import st_canvas from streamlit-drawable-canvas (not used now)
#from streamlit_drawable_canvas import st_canvas

from src.ann_model import ImprovedAnalogNeuralNetwork, pixels_to_voltages
from src.data_loader import get_data_loaders
from src.utils import plot_metrics

# Define file paths for model weights and training metrics.
MODEL_PATH = "model_weights.npz"
METRICS_PATH = "training_metrics.npz"

# Initialize session state for logs, metrics, test accuracy if not already set.
if "logs" not in st.session_state:
    st.session_state.logs = []
if "train_metrics" not in st.session_state:
    st.session_state.train_metrics = None
if "test_accuracy" not in st.session_state:
    st.session_state.test_accuracy = None

# ----- Custom CSS for Responsive Layout -----
st.markdown(
    """
    <style>
    /* General styles */
    .main {
        background-color: #f0f2f6;
        padding: 1rem;
    }
    .stApp {
        max-width: 100%;
        margin: 0 auto;
    }
    /* Sidebar customization */
    .css-1d391kg {  /* Streamlit's sidebar container */
        width: 300px;
    }
    /* Responsive adjustments for small screens */
    @media screen and (max-width: 768px) {
        .css-1d391kg {
            width: 100% !important;
        }
        .stApp {
            margin: 0;
        }
    }
    /* Headings color */
    h1, h2, h3 {
        color: #2e7bcf;
    }
    /* Button customization */
    .stButton>button {
        background-color: #2e7bcf;
        color: white;
        border: none;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# ----- App Title -----
st.title("DigitVision: Analog Neural Network Explorer")

# ----- Sidebar: Model Options -----
st.sidebar.header("Model Options")
load_trained = st.sidebar.checkbox("Load Trained Model", value=False)
retrain_model = st.sidebar.checkbox("Retrain Model", value=False)

if retrain_model:
    st.sidebar.subheader("Hyperparameter Tuning")
    hidden_size = st.sidebar.slider("Hidden Layer Size", min_value=50, max_value=300, value=100, step=10)
    epochs = st.sidebar.number_input("Epochs", min_value=1, max_value=50, value=10)
    learning_rate = st.sidebar.number_input("Learning Rate", min_value=0.0001, max_value=0.01, value=0.001, step=0.0001, format="%.4f")
else:
    hidden_size = 100
    epochs = 10
    learning_rate = 0.001

# ----- Data Loaders and Model Initialization -----
train_loader, val_loader, test_loader = get_data_loaders(batch_size=64)
ann = ImprovedAnalogNeuralNetwork(input_size=784, hidden_size=hidden_size, output_size=10)

# ----- Load Trained Model and Metrics if Available -----
if load_trained:
    if os.path.exists(MODEL_PATH):
        ann.load(MODEL_PATH)
        st.sidebar.success("Trained model loaded.")
        if os.path.exists(METRICS_PATH):
            metrics_data = np.load(METRICS_PATH)
            st.session_state.train_metrics = {
                "train_losses": metrics_data["train_losses"].tolist(),
                "val_losses": metrics_data["val_losses"].tolist(),
                "train_accuracies": metrics_data["train_accuracies"].tolist(),
                "val_accuracies": metrics_data["val_accuracies"].tolist()
            }
            if "test_accuracy" in metrics_data:
                st.session_state.test_accuracy = float(metrics_data["test_accuracy"])
        else:
            st.sidebar.info("No training metrics file found.")
    else:
        st.sidebar.error("No trained model found. Please retrain.")

# ----- Retraining Section with Persistent Logs, Graph, and Test Accuracy -----
if retrain_model:
    if st.sidebar.button("Retrain Model"):
        st.write("Retraining model... Please be patient, this may take several minutes.")
        log_placeholder = st.empty()
        st.session_state.logs = []
        def update_log(message):
            st.session_state.logs.append(message)
            log_placeholder.text("\n".join(st.session_state.logs))
        train_losses, val_losses, train_accuracies, val_accuracies = ann.train(
            train_loader, val_loader, epochs=epochs, learning_rate=learning_rate, log_callback=update_log
        )
        st.success("Model retrained successfully!")
        ann.save(MODEL_PATH)
        test_accuracy = ann.evaluate(test_loader)
        st.session_state.test_accuracy = test_accuracy
        st.write(f"**Test Accuracy:** {test_accuracy:.2f}%")
        st.session_state.train_metrics = {
            "train_losses": train_losses,
            "val_losses": val_losses,
            "train_accuracies": train_accuracies,
            "val_accuracies": val_accuracies
        }
        np.savez(METRICS_PATH,
                 train_losses=np.array(train_losses),
                 val_losses=np.array(val_losses),
                 train_accuracies=np.array(train_accuracies),
                 val_accuracies=np.array(val_accuracies),
                 test_accuracy=test_accuracy)

# ----- Main Interface Tabs -----
tabs = st.tabs(["Home", "Trained Metrics", "Sample Prediction", "Draw Digit (Coming Soon)"])

with tabs[0]:
    st.header("Welcome to DigitVision")
    st.write("""
        **Overview:**  
        DigitVision is an interactive explorer for a custom analog neural network designed for handwritten digit recognition using the MNIST dataset.  
        
        **Key Features:**  
        - **Load or Retrain the Model:** Use the sidebar to load a pre-trained model or retrain the network with custom hyperparameters.
        - **View Training Metrics:** Monitor training and validation loss/accuracy over epochs and examine the model's internal weight matrices.
        - **Sample Prediction:** Test the model on randomly selected MNIST test samples.
        - **Draw Digit (Coming Soon):** A future feature will let you draw a digit and see the model's prediction in real time.
        
        **How It Works:**  
        The network converts pixel values into voltage levels and propagates the data through hidden and output layers. Training adjusts the weight matrices (GM1 and GM2) to minimize prediction error.
        
        Enjoy exploring the inner workings of our analog neural network and discovering how it interprets handwritten digits!
    """)
    st.image("https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png", caption="Sample MNIST Digits", use_container_width=True)

with tabs[1]:
    st.header("Trained Metrics")
    if st.session_state.train_metrics is not None:
        tm = st.session_state.train_metrics
        fig_metrics = plot_metrics(tm["train_losses"], tm["val_losses"], tm["train_accuracies"], tm["val_accuracies"])
        st.pyplot(fig_metrics)
        if st.session_state.test_accuracy is not None:
            st.write(f"**Test Accuracy:** {st.session_state.test_accuracy:.2f}%")
        
        # Button to load and display the weight matrices.
        if st.button("Load Weights"):
            st.subheader("Model Weights")
            with st.expander("Show GM1 Weights"):
                st.dataframe(ann.Gm1)
            with st.expander("Show GM2 Weights"):
                st.dataframe(ann.Gm2)
    else:
        st.info("No training metrics available. Please retrain the model using the sidebar options.")

with tabs[2]:
    st.header("Sample Prediction from Test Data")
    if st.button("Show a Sample Prediction", key="sample_pred"):
        images, labels = next(iter(test_loader))
        idx = random.randint(0, len(labels) - 1)
        image = images[idx].view(-1, 28 * 28).numpy().flatten()
        true_label = labels[idx].item()
        X_voltages = pixels_to_voltages(image)
        predicted_label = ann.predict(X_voltages)
        st.write(f"**True Label:** {true_label}")
        st.write(f"**Predicted Label:** {predicted_label}")
        image_28 = image.reshape(28, 28)
        image_pil = Image.fromarray((image_28 * 255).astype(np.uint8))
        image_pil_half = image_pil.resize((14, 14), resample=Image.LANCZOS)
        fig, ax = plt.subplots(figsize=(2, 2))
        ax.imshow(image_pil_half, cmap="gray")
        ax.axis("off")
        st.pyplot(fig)

with tabs[3]:
    st.header("Draw Digit (Coming Soon)")
    st.info("This feature is under development and will be available in a future update.")


// File: src/data_loader.py
import torch
import torchvision
import torchvision.transforms as transforms

def load_mnist():
    """Downloads and loads the MNIST dataset."""
    transform = transforms.Compose([transforms.ToTensor()])
    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)
    testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)
    return trainset, testset

def get_data_loaders(batch_size=64, val_split=0.2):
    """Splits the training set into training and validation loaders."""
    trainset, testset = load_mnist()
    train_size = int((1 - val_split) * len(trainset))
    val_size = len(trainset) - train_size
    train_subset, val_subset = torch.utils.data.random_split(trainset, [train_size, val_size])
    
    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size, shuffle=True)
    val_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size, shuffle=False)
    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)
    
    return train_loader, val_loader, test_loader


// File: src/__init__.py


// File: src/utils.py
import matplotlib.pyplot as plt

def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies):
    """Plots training and validation loss/accuracy metrics."""
    epochs = range(1, len(train_losses) + 1)
    
    fig, axs = plt.subplots(1, 2, figsize=(12, 5))
    
    # Plot Loss
    axs[0].plot(epochs, train_losses, 'b-', label='Train Loss')
    axs[0].plot(epochs, val_losses, 'r-', label='Validation Loss')
    axs[0].set_title('Loss')
    axs[0].set_xlabel('Epoch')
    axs[0].set_ylabel('Loss')
    axs[0].legend()
    axs[0].grid(True)
    
    # Plot Accuracy
    axs[1].plot(epochs, train_accuracies, 'b-', label='Train Accuracy')
    axs[1].plot(epochs, val_accuracies, 'r-', label='Validation Accuracy')
    axs[1].set_title('Accuracy (%)')
    axs[1].set_xlabel('Epoch')
    axs[1].set_ylabel('Accuracy')
    axs[1].legend()
    axs[1].grid(True)
    
    plt.tight_layout()
    return fig


// File: src/ann_model.py
import numpy as np

def pixels_to_voltages(pixels, min_voltage=-5.0, max_voltage=5.0):
    """Converts pixel values (normalized 0-1) to voltage range."""
    return pixels * (max_voltage - min_voltage) + min_voltage

def relu(x):
    return np.maximum(0, x)

def relu_derivative(x):
    return (x > 0).astype(float)

def sigmoid(x):
    pos_mask = (x >= 0)
    neg_mask = (x < 0)
    z = np.zeros_like(x)
    z[pos_mask] = np.exp(-x[pos_mask])
    z[neg_mask] = np.exp(x[neg_mask])
    top = np.ones_like(x)
    top[neg_mask] = z[neg_mask]
    return top / (1 + z)

def sigmoid_derivative(x):
    s = sigmoid(x)
    return s * (1 - s)

class ImprovedAnalogNeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size):
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size

        # Weight initialization using uniform distribution based on layer sizes
        limit1 = np.sqrt(6 / (input_size + hidden_size))
        self.Gm1 = np.random.uniform(-limit1, limit1, (hidden_size, input_size))
        self.b1 = np.zeros(hidden_size)

        limit2 = np.sqrt(6 / (hidden_size + output_size))
        self.Gm2 = np.random.uniform(-limit2, limit2, (output_size, hidden_size))
        self.b2 = np.zeros(output_size)

    def forward(self, X_voltages):
        self.z1 = np.dot(self.Gm1, X_voltages) + self.b1
        self.a1 = relu(self.z1)
        self.z2 = np.dot(self.Gm2, self.a1) + self.b2
        self.a2 = sigmoid(self.z2)
        return self.a2

    def backward(self, X_voltages, y_onehot, output, learning_rate=0.001):
        error = output - y_onehot
        delta2 = error * sigmoid_derivative(self.z2)
        dGm2 = np.outer(delta2, self.a1)

        error_hidden = np.dot(self.Gm2.T, delta2)
        delta1 = error_hidden * relu_derivative(self.z1)
        dGm1 = np.outer(delta1, X_voltages)

        self.Gm2 -= learning_rate * dGm2
        self.b2 -= learning_rate * delta2
        self.Gm1 -= learning_rate * dGm1
        self.b1 -= learning_rate * delta1

    def train(self, train_loader, val_loader, epochs=50, learning_rate=0.001, log_callback=None):
        train_losses = []
        val_losses = []
        train_accuracies = []
        val_accuracies = []

        for epoch in range(epochs):
            total_train_loss = 0
            train_correct = 0
            train_total = 0

            for images, labels in train_loader:
                images = images.view(-1, 28*28).numpy()
                labels_onehot = np.eye(self.output_size)[labels.numpy()]

                for X_pixels, y_onehot in zip(images, labels_onehot):
                    X_voltages = pixels_to_voltages(X_pixels)
                    output = self.forward(X_voltages)
                    loss = -np.sum(y_onehot * np.log(output + 1e-10))
                    total_train_loss += loss

                    self.backward(X_voltages, y_onehot, output, learning_rate=learning_rate)

                    if np.argmax(output) == np.argmax(y_onehot):
                        train_correct += 1
                    train_total += 1

            avg_train_loss = total_train_loss / len(train_loader.dataset)
            train_accuracy = 100 * train_correct / train_total

            total_val_loss = 0
            val_correct = 0
            val_total = 0

            for images, labels in val_loader:
                images = images.view(-1, 28*28).numpy()
                labels_onehot = np.eye(self.output_size)[labels.numpy()]

                for X_pixels, y_onehot in zip(images, labels_onehot):
                    X_voltages = pixels_to_voltages(X_pixels)
                    output = self.forward(X_voltages)
                    loss = -np.sum(y_onehot * np.log(output + 1e-10))
                    total_val_loss += loss

                    if np.argmax(output) == np.argmax(y_onehot):
                        val_correct += 1
                    val_total += 1

            avg_val_loss = total_val_loss / len(val_loader.dataset)
            val_accuracy = 100 * val_correct / val_total

            train_losses.append(avg_train_loss)
            val_losses.append(avg_val_loss)
            train_accuracies.append(train_accuracy)
            val_accuracies.append(val_accuracy)

            log_msg = (f"Epoch {epoch+1}/{epochs}, "
                       f"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, "
                       f"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%")
            print(log_msg)
            if log_callback:
                log_callback(log_msg)

        return train_losses, val_losses, train_accuracies, val_accuracies

    def predict(self, X_voltages):
        output = self.forward(X_voltages)
        return np.argmax(output)

    def evaluate(self, test_loader):
        correct = 0
        total = 0
        for images, labels in test_loader:
            images = images.view(-1, 28*28).numpy()
            labels = labels.numpy()
            for X_pixels, label in zip(images, labels):
                X_voltages = pixels_to_voltages(X_pixels)
                if self.predict(X_voltages) == label:
                    correct += 1
                total += 1
        accuracy = 100 * correct / total
        print(f"Test Accuracy: {accuracy:.2f}%")
        return accuracy

    def save(self, file_path):
        """Saves model weights to a file."""
        np.savez(file_path, Gm1=self.Gm1, b1=self.b1, Gm2=self.Gm2, b2=self.b2)
        print(f"Model saved to {file_path}")

    def load(self, file_path):
        """Loads model weights from a file."""
        data = np.load(file_path)
        self.Gm1 = data['Gm1']
        self.b1 = data['b1']
        self.Gm2 = data['Gm2']
        self.b2 = data['b2']
        print(f"Model loaded from {file_path}")


// File: src/train.py
import torch
from src.data_loader import get_data_loaders
from src.ann_model import ImprovedAnalogNeuralNetwork
from src.utils import plot_metrics

def main():
    # Create data loaders
    train_loader, val_loader, test_loader = get_data_loaders(batch_size=64)
    
    # Initialize model with default hyperparameters
    ann = ImprovedAnalogNeuralNetwork(input_size=784, hidden_size=100, output_size=10)
    
    # Train the model (adjust epochs and learning_rate as needed)
    train_losses, val_losses, train_accuracies, val_accuracies = ann.train(train_loader, val_loader, epochs=10, learning_rate=0.001)
    
    # Evaluate on test set
    ann.evaluate(test_loader)
    
    # Save the trained model
    ann.save("model_weights.npz")
    
    # Plot and display metrics
    fig = plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies)
    fig.show()

if __name__ == '__main__':
    main()


